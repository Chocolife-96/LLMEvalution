# /root/model/miniconda3/envs/purellm/bin/python3.10 lmeval.py --model hf-causal-experimental --model_args pretrained=/root/model/models/hf-llama-2-7b,load_in_4bit=True,bnb_4bit_quant_type="nf4" --batch_size=2 --tasks piqa,hellaswag,lambada_openai
# /root/model/miniconda3/envs/purellm/bin/python3.10 lmeval.py --model hf-causal-experimental --model_args pretrained=/root/model/qlora/ckpt_nf4_large_bs/checkpoint-520,load_in_4bit=True,bnb_4bit_quant_type="nf4" --batch_size=2 --tasks piqa,hellaswag,lambada_openai
# /root/model/miniconda3/envs/purellm/bin/python3.10 lmeval.py --model hf-causal-experimental --model_args pretrained=/root/model/qlora/ckpt_nf4_large_bs/checkpoint-600,load_in_4bit=True,bnb_4bit_quant_type="nf4" --batch_size=2 --tasks piqa,hellaswag,lambada_openai
# /root/model/miniconda3/envs/purellm/bin/python3.10 lmeval.py --model hf-causal-experimental --model_args pretrained=/root/model/qlora/ckpt_nf4_large_bs/checkpoint-700,load_in_4bit=True,bnb_4bit_quant_type="nf4" --batch_size=2 --tasks piqa,hellaswag,lambada_openai
# /root/model/miniconda3/envs/purellm/bin/python3.10 lmeval.py --model hf-causal-experimental --model_args pretrained=/root/model/qlora/ckpt_nf4_large_bs/checkpoint-800,load_in_4bit=True,bnb_4bit_quant_type="nf4" --batch_size=2 --tasks piqa,hellaswag,lambada_openai
# /root/model/miniconda3/envs/purellm/bin/python3.10 lmeval.py --model hf-causal-experimental --model_args pretrained=/root/model/qlora/ckpt_nf4_large_bs/checkpoint-900,load_in_4bit=True,bnb_4bit_quant_type="nf4" --batch_size=2 --tasks piqa,hellaswag,lambada_openai

/root/model/miniconda3/envs/purellm/bin/python3.10 lmeval.py --model hf-causal-experimental --model_args pretrained=/root/model/qlora/ckpts/ckpt_fp16_Pretochat/checkpoint-80 --num_fewshot=5 --batch_size=8 --tasks hendrycksTest-* --output_path /root/model/qlora/ckpts/ckpt_fp16_Pretochat/checkpoint-80/mmlu_fp16.json
/root/model/miniconda3/envs/purellm/bin/python3.10 lmeval.py --model hf-causal-experimental --model_args pretrained=/root/model/qlora/ckpts/ckpt_fp16_Pretochat/checkpoint-80,load_in_4bit="True",bnb_4bit_quant_type="nf4" --num_fewshot=5 --batch_size=8 --tasks hendrycksTest-* --output_path /root/model/qlora/ckpts/ckpt_fp16_Pretochat/checkpoint-80/mmlu_nf4.json
/root/model/miniconda3/envs/purellm/bin/python3.10 lmeval.py --model hf-causal-experimental --model_args pretrained=/root/model/qlora/ckpts/ckpt_fp16_Pretochat/checkpoint-160 --num_fewshot=5 --batch_size=8 --tasks hendrycksTest-* --output_path /root/model/qlora/ckpts/ckpt_fp16_Pretochat/checkpoint-160/mmlu_fp16.json
/root/model/miniconda3/envs/purellm/bin/python3.10 lmeval.py --model hf-causal-experimental --model_args pretrained=/root/model/qlora/ckpts/ckpt_fp16_Pretochat/checkpoint-160,load_in_4bit="True",bnb_4bit_quant_type="nf4" --num_fewshot=5 --batch_size=8 --tasks hendrycksTest-* --output_path /root/model/qlora/ckpts/ckpt_fp16_Pretochat/checkpoint-160/mmlu_nf4.json